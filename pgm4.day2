import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Generate random data for demonstration
np.random.seed(0)
X = 6 * np.random.rand(100, 1) - 3
y = 0.5 * X**2 + X + 2 + np.random.randn(100, 1)

# Fit Linear Regression
lin_reg = LinearRegression()
lin_reg.fit(X, y)
y_lin_pred = lin_reg.predict(X)
lin_mse = mean_squared_error(y, y_lin_pred)

# Fit Polynomial Regression
poly_features = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly_features.fit_transform(X)
poly_reg = LinearRegression()
poly_reg.fit(X_poly, y)
y_poly_pred = poly_reg.predict(X_poly)
poly_mse = mean_squared_error(y, y_poly_pred)

# Plot results
plt.scatter(X, y, color='blue', label='Data')
plt.plot(X, y_lin_pred, color='red', label=f'Linear Regression (MSE={lin_mse:.2f})')
plt.plot(X, y_poly_pred, color='green', label=f'Polynomial Regression (MSE={poly_mse:.2f})')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Linear vs Polynomial Regression')
plt.legend()
plt.show()
